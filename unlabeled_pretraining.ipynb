{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ba9f45-6827-4d59-9889-1757f314f1fd",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "The resources for training a transformer model with Language Modeling objective can be found in the Huggingface transformer library under the resources for Causal Language Modeling task. Here is a code snippet which demonstrates how to train a Bert Model with a language modeling head.\n",
    "\n",
    "The Bert model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of cross-attention is added between the self-attention layers, following the architecture described in Attention is all you need article. Given that we want to use `BertLMHeadModel` as a standalone model, we shall add `is_decoder=True.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675fc5d0-d7c2-485a-9f1f-a07a70b2f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import logging, BertConfig, BertTokenizer, BertLMHeadModel, BertForMaskedLM, BertForNextSentencePrediction\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e64ae8-9cbd-430e-8e48-57aa5c3f9643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n",
      "torch.Size([1, 11, 30522])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "config.is_decoder = True\n",
    "model = BertLMHeadModel.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "inputs = tokenizer(\"California a well known for the great startups\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "prediction_logits = outputs.logits\n",
    "\n",
    "print(inputs['input_ids'].shape)  # torch.Size([1, 11])\n",
    "print(prediction_logits.shape)  # torch.Size([1, 11, 30522])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73fb7f5-0076-4562-af66-f0b93e080119",
   "metadata": {},
   "source": [
    "# Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0965ca65-93cc-4b90-888e-3ec9ae438102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n",
      "torch.Size([1, 11, 30522])\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"California a well known for the great [MASK].\", return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "print(inputs['input_ids'].shape)  # torch.Size([1, 11])\n",
    "print(prediction_logits.shape)  # torch.Size([1, 11, 30522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df9ac9a-6055-43ec-87a8-c1ce83d967cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was walking in the park while the car drove away\n",
      "I was walking in the rain while the car drove away\n",
      "I was walking in the dark while the car drove away\n",
      "I was walking in the grass while the car drove away\n",
      "I was walking in the street while the car drove away\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sequence = f\"I was walking in the {tokenizer.mask_token} while the car drove away\"\n",
    "\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(**inputs).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d33927-5e57-43b1-b467-b148c231733e",
   "metadata": {},
   "source": [
    "# Next Sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1b6d17-a0cc-47a3-aeac-33532621a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.285246849060059 -6.113039970397949\n"
     ]
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "prompt = \"Mercury is the first plant in the solar system\"\n",
    "next_sentence = \"Venus is the second planet in the solar system\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "print(logits[0, 0].item(), logits[0, 1].item())  # 6.285 -6.113. It can be next sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba651fa-e407-4b0a-a631-4c761dd92916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6754419803619385 3.869070529937744\n"
     ]
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "prompt = \"Mercury is the first plant in the solar system\"\n",
    "next_sentence = \"My name is Tom\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
    "logits = outputs.logits\n",
    "print(logits[0, 0].item(), logits[0, 1].item())  # -1.675 3.869. next sentence was random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neptune",
   "language": "python",
   "name": "neptune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
